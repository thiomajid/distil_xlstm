use_tfla: true
xlstm_config:
  vocab_size: 49_152
  context_length: 256
  num_blocks: 12
  embedding_dim: 256
  # slstm_at: [0, 2, 4]

  mlstm_block:
    mlstm:
      conv1d_kernel_size: 4
      qkv_proj_blocksize: 32
      num_heads: 4

  slstm_block:
    slstm:
      backend: "cuda"
      num_heads: 4
      conv1d_kernel_size: 4
      bias_init: "powerlaw_blockdependent"

    feedforward:
      proj_factor: 1.7
      act_fn: "gelu"

tfla_config:
  embedding_dim: 32
  num_heads: 8
  num_blocks: 6
  vocab_size: 32_000
  use_bias: false
  chunkwise_kernel: "chunkwise--triton_xl_chunk"
  sequence_kernel: "native_sequence__triton"
  step_kernel: "triton"
  mode: "train"
  autocast_kernel_dtype: "float16"
  inference_state_dtype: "float16"
  weight_mode: "fused"
